<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[如何利用 Python 抓取 Twitter 的内容]]></title>
    <url>%2F2017%2F10%2F20%2F2017-10-20-1%2F</url>
    <content type="text"><![CDATA[这篇总结一下初次使用 python 抓取推文的学习心得吧，其实也就是跑了下书中的代码。技术流程就是前文展示的那种，那么这里就按照这个流程来一遍吧。（本部分涉及到书中的 Chap2-3 ） 验证登入 Twitter App 获取 key1、进入网站2、新建应用3、获取以下 key 值consumer key， consumer secret， access token， access secret 运行通用型认证代码1234567891011121314151617181920212223242526272829303132333435# 用于获得推特的准入许可（第一步）import osimport sysfrom tweepy import APIfrom tweepy import OAuthHandlerdef get_twitter_auth(): """启动 Twitter 验证 返回: tweepy.OAuthHandler 对象 """ try: # 下面的代码不知道如何解决，设置了环境变量，但是依然有错误，所以采用直接形式 #consumer_key = os.environ['TWITTER_CONSUMER_KEY'] #consumer_secret = os.environ['TWITTER_CONSUMER_SECRET'] #access_token = os.environ['TWITTER_ACCESS_TOKEN'] #access_secret = os.environ['TWITTER_ACCESS_SECRET'] consumer_key = '自己填' consumer_secret = '自己填' access_token = '自己填' access_secret = '自己填' except KeyError: sys.stderr.write("TWITTER_* environment variables not set\n") sys.exit(1) auth = OAuthHandler(consumer_key, consumer_secret) auth.set_access_token(access_token, access_secret) return authdef get_twitter_client(): """启动 Twitter API 客户端 返回: tweepy.API 对象 """ auth = get_twitter_auth() # 这里要注意设置代理的网址 client = API(auth,proxy="自己填") return client 数据收集数据清理和预处理建模和分析结果展示1、第一步：获取许可并登入包含两部分：get_twitter_auth() 获得许可证get_twitter_client() 登入服务器 小实验：获取自己主页时间线的前十条tweepy.Cursortweepy.Status 小实验2: 获取主页200条并存入 json自己主页最多 800条；别人主页最多 3200条； tweet 的数据结构streaming APICustomListener class StreamListener on_data() on_error()#19thCPC #19thPartyCongress 数据分析标签频率；推文标签分布；提及人频率； 文本分析Tokenization 分词stop word removal 停顿词 时间序列分析粉丝状况 在量很大的情况下，选择 set 或者 numpy 来计算； 测量影响力Term Frequency (TF)Inverse Document Frequency (IDF)TF-IDF statistics 评论关系未完全检测到，可能跟数据有关 地图绘制]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎么理解 Python 爬虫]]></title>
    <url>%2F2017%2F10%2F20%2F2017-10-20%2F</url>
    <content type="text"><![CDATA[由于自己的研究需要爬取 Twitter 和 Facebook 的社交数据，但自己又没有真正爬取过，那么我就来好好学习一下啦。 #选择一本书我选择了《Mastering social media mining with Python》这本书，里面的讲解还是很直接的，干货多方便我快速掌握。 #了解一些理论第一章是 Social media - challenges and opportunities ，讲的是一些爬虫的基本知识，还有一些技术展示，重在培养对爬虫的兴趣。 对社交媒体的理解Internet-based applicationsUser-generated contentNetworking 本书要解决的问题how to extract useful knowledge from the data coming from the social media? knowledge hierarchy 社交媒体挖掘的机遇Application Programming Interface (API)Representational State Transfer (REST)RESTful API 社交媒体挖掘的挑战big datastructured dataunstructured data semi-structured data data integrity data access research and development (R&amp;D) processes 社交媒体挖掘的技术流程1、验证 Authentication2、数据收集 Data collection3、数据清理和预处理 Data cleaning and pre-processing4、建模和分析 Modeling and analysis5、结果展示 Result presentation Open Authorization (OAuth)a user, consumer (our application), and resource provider (the social media platform). Text miningGraph mining Python tools for data sciencePython 的优点Declarative and intuitive syntaxRich ecosystem for data processingEfficiency Python 版本3.4+ and 3.5+pip and virtualenvvirtualenv 管理虚拟环境和安装依赖环境Conda, Anaconda, and Miniconda 数据分析工具NumPy and pandasNaming conventionsnumpy as np; pandas as pd; 机器学习Supervised learningNaive Bayes (NB)Support Vector Machine (SVM)Neural Networks (NN)training datatest dataUnsupervised learning]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[终于弄好了～]]></title>
    <url>%2F2017%2F10%2F19%2Fhello-world%2F</url>
    <content type="text"><![CDATA[花了一点时间弄这个，可以建一个自己的博客也是很好了。]]></content>
      <categories>
        <category>生活日志</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
