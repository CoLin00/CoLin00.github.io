<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>小站一会</title>
    <link>http://colin00.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>记录生活和自己。</description>
    <pubDate>Tue, 07 Nov 2017 07:41:24 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Journal of Communication, Volume 67, Issue 1</title>
      <link>http://colin00.github.io/2017/10/30/2017-10-30/</link>
      <guid>http://colin00.github.io/2017/10/30/2017-10-30/</guid>
      <pubDate>Mon, 30 Oct 2017 15:43:45 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;img src=&quot;/images/jcom.jpg&quot; alt=&quot;jcom&quot;&gt;&lt;/p&gt;
&lt;p&gt;本期 Journal of Communication 主要关注了冲突报道、网络隐私问题、政治新闻报道、父母对孩子使用互联网的介入、媒介可供性以及公民的政治讨论等议题。&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="/css/lib/hint.min.css"><p><img src="/images/jcom.jpg" alt="jcom"></p><p>本期 Journal of Communication 主要关注了冲突报道、网络隐私问题、政治新闻报道、父母对孩子使用互联网的介入、媒介可供性以及公民的政治讨论等议题。</p><a id="more"></a> <h1 id="融合新闻？以巴冲突在国内和全球报道上异同的纵向研究"><a href="#融合新闻？以巴冲突在国内和全球报道上异同的纵向研究" class="headerlink" title="融合新闻？以巴冲突在国内和全球报道上异同的纵向研究"></a>融合新闻？以巴冲突在国内和全球报道上异同的纵向研究</h1><p><strong>Convergent News? A Longitudinal Study of Similarity and Dissimilarity in the Domestic and Global Coverage of the Israeli-Palestinian Conflict</strong></p><div class="note info"><p><a href="https://doi.org/10.1111/jcom.12272" target="_blank" rel="external">Baden, C., &amp; Tenenboim-Weinblatt, K. (2017). Convergent News? A Longitudinal Study of Similarity and Dissimilarity in the Domestic and Global Coverage of the Israeli-Palestinian Conflict. Journal of Communication, 67(1), 1–25. </a> </p></div><p>同一事件的新闻报道同时受到同质和异质因素的影响。在这篇论文中，我们通过分析在13个以色列、巴勒斯坦和国际主流媒体中超过十年的以巴冲突报道，研究了在不同媒体中的冲突报道是否以及什么时候变得越来越相似或者不同。我们区分了新闻中持续相似、逐渐融合和短暂离合的动因，并将它们与20多万新闻文本中明显的概念关系模式相关联。我们发现新闻中存在一种缓慢的、语境依赖的融合趋势，以及在有关重大冲突事件的解释中的暂时联合和分离。本研究探讨了潜在的交互作用，并指出研究当前全球新闻业变革的意义。</p><h1 id="网络隐私顾虑和隐私管理：一个文献荟萃分析"><a href="#网络隐私顾虑和隐私管理：一个文献荟萃分析" class="headerlink" title="网络隐私顾虑和隐私管理：一个文献荟萃分析"></a>网络隐私顾虑和隐私管理：一个文献荟萃分析</h1><p><strong>Online Privacy Concerns and Privacy Management: A Meta-Analytical Review</strong></p><div class="note info"><p><a href="https://doi.org/10.1111/jcom.12276" target="_blank" rel="external">Baruh, L., Secinti, E., &amp; Cemalcilar, Z. (2017). Online Privacy Concerns and Privacy Management: A Meta-Analytical Review. Journal of Communication, 67(1), 26–53.</a> </p></div><p>本文使用了荟萃分析方法研究了个人的“隐私顾虑”和“隐私素养”能否预测人们网络服务和社交网站的使用、人们是否分享信息和是否采纳隐私保护措施。分析选用了来自34个国家（n = 75,269）的共计166项研究。隐私顾虑并不能预测社交网站的使用情况，这符合隐私悖论（privacy paradox）的假设。但是关心隐私的用户几乎不会使用在线服务以及分享信息，他们更可能运用隐私保护措施。除了信息分享，他们在意图和行为上也存在一致性。本研究也认为隐私素养在提高隐私保护措施使用能力上有重要作用。研究发现适用于不同性别、文化导向和国家法律体系。</p><blockquote><p>Meta 分析是一种将多项研究结果进行定量合成分析的统计学方法，始于20世纪70~80年代，最初被定义为“收集大量单项试验进行结果整合的统计学分析”；1991年，Fleiss 提出了较严谨和准确的定义，“Meta 分析是用于比较和综合针对同一科学问题研究结果的统计学方法，其结论是否有意义取决于纳入研究的质量”。这说明并非所有 Meta 分析都能得出高质量结果和结论，只有对纳入研究进行同质性检验，分析异质性的原因，按同质性因素进行合并的 Meta 分析才可能有意义。仅纳入随机对照试验（RCT）的 Meta 分析得出的结果一般偏倚较小，其结论准确性远比单项试验高。</p></blockquote><h1 id="选择严肃还是讽刺，支持还是激动人心的新闻？政党的选择性接触与嘲讽新闻网络视频"><a href="#选择严肃还是讽刺，支持还是激动人心的新闻？政党的选择性接触与嘲讽新闻网络视频" class="headerlink" title="选择严肃还是讽刺，支持还是激动人心的新闻？政党的选择性接触与嘲讽新闻网络视频"></a>选择严肃还是讽刺，支持还是激动人心的新闻？政党的选择性接触与嘲讽新闻网络视频</h1><p><strong>Selecting Serious or Satirical, Supporting or Stirring News? Selective Exposure to Partisan versus Mockery News Online Videos</strong></p><div class="note info"><p><a href="https://doi.org/10.1111/jcom.12271" target="_blank" rel="external">Knobloch-Westerwick, S., &amp; Lavis, S. M. (2017). Selecting Serious or Satirical, Supporting or Stirring News? Selective Exposure to Partisan versus Mockery News Online Videos. Journal of Communication, 67(1), 54–81.</a> </p></div><p>本研究将认知不协调理论与娱乐-教育体系（entertainment-education frameworks）相结合来分析新闻的选择性和效果。我们用网络视频来检测对讽刺和政党报道的选择性接触，并以此检验有关克服反抗说服性信息的研究假设。实验（n=146）显示新闻的选择在立场（保守 vs. 自由）和题材（严肃政党报道 vs. 讽刺报道）上有所不同。研究结果显示出政治利益培植了严肃政党报道的选择。与政党一致的视频更常被选择；只有在讽刺报道视频面前，民主党并不展现如此稳固的偏见。选择的讽刺报道影响了内部的政治效果，并且选择的在线视频依据信息的立场引起了态度的强化。</p><h1 id="最大化儿童的互联网使用机会和最小化面临的风险：父母介入的新兴策略中数字技能的作用"><a href="#最大化儿童的互联网使用机会和最小化面临的风险：父母介入的新兴策略中数字技能的作用" class="headerlink" title="最大化儿童的互联网使用机会和最小化面临的风险：父母介入的新兴策略中数字技能的作用"></a>最大化儿童的互联网使用机会和最小化面临的风险：父母介入的新兴策略中数字技能的作用</h1><p><strong>Maximizing Opportunities and Minimizing Risks for Children Online: The Role of Digital Skills in Emerging Strategies of Parental Mediation</strong></p><div class="note info"><p><a href="https://doi.org/10.1111/jcom.12277" target="_blank" rel="external">Livingstone, S., Ólafsson, K., Helsper, E. J., Lupiáñez-Villanueva, F., Veltri, G. A., &amp; Folkvord, F. (2017). Maximizing Opportunities and Minimizing Risks for Children Online: The Role of Digital Skills in Emerging Strategies of Parental Mediation. Journal of Communication, 67(1), 82–105. </a></p></div><p>随着互联网在家庭中的广泛使用，父母不仅尝试最大化它们孩子使用互联网的机会，也在尽可能降低互联网使用的风险。我们调查了8个欧洲国家中6-14岁孩子的父母（N=6,400）。因子分析揭示了2个父母介入策略。介入的实施与提高互联网使用机会有关，但要面临存在的风险。这个策略包括了安全措施，对儿童机构的反应，以及在父母或孩子有一定数字技能之时的应用，因此这个策略可能不会造成危害。有限介入与面对互联网更少的风险有关，但要以互联网使用机会为代价，这再次审视了把媒介使用作为主要问题的政策建议。本研究证实了当父母或孩子数字技能都较低的时候，有可能保护脆弱孩子的安全，然而也会不利于他们学习数字技能。</p><h1 id="组织性媒介可供性：操作化和媒介使用的关联"><a href="#组织性媒介可供性：操作化和媒介使用的关联" class="headerlink" title="组织性媒介可供性：操作化和媒介使用的关联"></a>组织性媒介可供性：操作化和媒介使用的关联</h1><p><strong>Organizational Media Affordances: Operationalization and Associations with Media Use</strong></p><div class="note info"><p><a href="https://doi.org/10.1111/jcom.12273" target="_blank" rel="external">Rice, R. E., Evans, S. K., Pearce, K. E., Sivunen, A., Vitak, J., &amp; Treem, J. W. (2017). Organizational Media Affordances: Operationalization and Associations with Media Use. Journal of Communication, 67(1), 106–130. </a></p></div><p>越来越多研究将可供性这个概念用于分析组织语境下的信息和传播技术（ICTs）。然而，几乎没有研究对可供性进行操作化，以限定比较和程序化的研究。本文简要地从一般的和媒体的角度来回顾了可供性的概念化和可能情况，然后介绍了作为组织资源的组织媒体可供性概念。本研究利用来自一家北欧大型媒体组织的问卷调查数据，识别了六个可靠且有效的组织媒体可供性：遍在、可编辑、自我呈现、可检索、可访问和意识。基于在三个组织层级之一的十种媒体使用频率的八级媒介量表与这些可供性各有不同。来自这项研究的概念化、测量方法和结果能够为今后的组织传播和传播技术研究提供参考。</p><h1 id="什么时候我们停止讨论政治：争议时期的对话维护和关闭"><a href="#什么时候我们停止讨论政治：争议时期的对话维护和关闭" class="headerlink" title="什么时候我们停止讨论政治：争议时期的对话维护和关闭"></a>什么时候我们停止讨论政治：争议时期的对话维护和关闭</h1><p><strong>When We Stop Talking Politics: The Maintenance and Closing of Conversation in Contentious Times</strong></p><div class="note info"><p><a href="https://doi.org/10.1111/jcom.12280" target="_blank" rel="external">Wells, C., Cramer, K. J., Wagner, M. W., Alvarez, G., Friedland, L. A., Shah, D. V., … Franklin, C. (2017). When We Stop Talking Politics: The Maintenance and Closing of Conversation in Contentious Times. Journal of Communication, 67(1), 131–157.</a></p></div><p>尽管公民讨论政治对民主而言有很重要的意义，传播学的研究并未考虑到这种讨论该怎样承受住来自我们公民文化的压力。我们分析了在一个典型的政治争议案例期间的政治讨论：2012年威斯康星州州长 Scott Walker 的罢免。结合了定性和定量的方法，我们发现公民文化分歧产生于许多市民觉得政治讨论无法继续的情况中。个体在错误的争端阵营中，受到职业性质、地理位置和其他个人环境因素的影响，更倾向于分裂。我们的研究结果质疑了在民主功能性的影响中，政治讨论能够在多极化和碎片化的时期为政治和社会差异之间搭建起沟通桥梁的能力。</p>]]></content:encoded>
      
      <comments>http://colin00.github.io/2017/10/30/2017-10-30/#disqus_thread</comments>
    </item>
    
    <item>
      <title>烦闷的奔波</title>
      <link>http://colin00.github.io/2017/10/29/2017-10-29/</link>
      <guid>http://colin00.github.io/2017/10/29/2017-10-29/</guid>
      <pubDate>Sun, 29 Oct 2017 10:21:17 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;img src=&quot;http://oyrmgf04y.bkt.clouddn.com/2017-11-03-15092727743790.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;你总是疲惫地仰望天空，&lt;br&gt;然而，你却看不到未来的银河。&lt;br&gt;
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="/css/lib/hint.min.css"><p><img src="http://oyrmgf04y.bkt.clouddn.com/2017-11-03-15092727743790.jpg" alt=""></p><p>你总是疲惫地仰望天空，<br>然而，你却看不到未来的银河。<br><a id="more"></a> </p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=32897749&auto=0&height=66"></iframe><p>这几天为自己未来操心操力，时紧时松，也是够了。</p><p>不知道该碎碎语什么，逐渐发觉自己对世界的认知太过单纯，单纯地以为只有一颗理想主义的心就能获得理想主义的青睐，然后可以坚持原则，没用实质的东西跟别人表示我很行，并不意味着我不行啊，然而世界的话语体系是建立在“看得见”的事实之上，没有人真会耐心地等待你的努力，没有人会真地等你发挥你的潜力，所有成绩都是靠象征性的数字或者纸张来表达的。如果你没有纸张，你就没有成绩；如果你没有数字，你就没有成果。人的存在束缚在了这些零零碎碎的体系之中，然后我们以此为生，世世代代。</p><p>这就是现实啊，我是不是该摇醒我自己，看看周围，看看镜子中的自己。</p>]]></content:encoded>
      
      <comments>http://colin00.github.io/2017/10/29/2017-10-29/#disqus_thread</comments>
    </item>
    
    <item>
      <title>如何利用 Python 抓取 Twitter 的内容</title>
      <link>http://colin00.github.io/2017/10/20/2017-10-20-1/</link>
      <guid>http://colin00.github.io/2017/10/20/2017-10-20-1/</guid>
      <pubDate>Fri, 20 Oct 2017 07:05:35 GMT</pubDate>
      <description>
      
        &lt;p&gt;这篇总结一下初次使用 python 抓取推文的学习心得吧，其实也就是跑了下书中的代码。技术流程就是前文展示的那种，那么这里就按照这个流程来一遍吧。&lt;br&gt;（本部分涉及到书中的 Chap2-3 ）&lt;br&gt;
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="/css/lib/hint.min.css"><p>这篇总结一下初次使用 python 抓取推文的学习心得吧，其实也就是跑了下书中的代码。技术流程就是前文展示的那种，那么这里就按照这个流程来一遍吧。<br>（本部分涉及到书中的 Chap2-3 ）<br><a id="more"></a><br>我们利用 Python 中的 Tweepy 模块来进行 Twitter 抓取。<br>本部分使用的编辑器是：Jupyter Notebook<br>【需要添加安装教程】<br>使用的 Python 版本：3.6.4 or 3.0+<br>主要用的模块：Tweepy</p><h1 id="Twitter-许可验证"><a href="#Twitter-许可验证" class="headerlink" title="Twitter 许可验证"></a>Twitter 许可验证</h1><h2 id="创建-Twitter-App-获取认证所需信息"><a href="#创建-Twitter-App-获取认证所需信息" class="headerlink" title="创建 Twitter App 获取认证所需信息"></a>创建 Twitter App 获取认证所需信息</h2><p>【需要添加认证方法教程】<br>1、进入网站 <a href="https://apps.twitter.com" target="_blank" rel="external">Twitter Application Management</a> 。<br>2、点击 <code>Creat New App</code> 新建应用。<br>3、新建完之后，点开刚建的 App，在 <code>Keys and Access Tokens</code> 页面中记录以下项目的值：<br><code>Consumer Key</code> ， <code>Consumer Secret</code> ， <code>Access Token</code> ， <code>Access Token Secret</code>。<br>4、注意 <code>Consumer Key</code> 和 <code>Consumer Secret</code> 还分别是 <code>API Key</code> 和 <code>API Secret</code> 。</p><h2 id="获得-Twitter-认证"><a href="#获得-Twitter-认证" class="headerlink" title="获得 Twitter 认证"></a>获得 Twitter 认证</h2><p>Twitter 的认证有两种方法，一种是用户自己登入进去的 <strong>User authentication</strong> ( <code>OAuthHandler</code> ) <sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="关于`OAuth` 可参考：[理解 OAuth 2.0](http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html) 。 ">[1]</span></a></sup> ；另一种是以 APP 方式登入进去的 <strong>Application-only authentication</strong> ( <code>AppAuthHandler</code> )。<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Twitter 的这两种 API 的认证模式可以参考官方介绍：[Twitter API Authentication Model](https://developer.twitter.com/en/docs/basics/authentication/overview/oauth)。">[2]</span></a></sup> 两种方法在使用权限上都有限制，通常我们爬取 Twitter ，感兴趣的是其他用户的内容而非自己的，所以爬取主要是针对指定用户或者是指定关键词的相关内容。在调用 <code>Search API</code> 爬取方面，<strong>Application-only authentication</strong>  的认证模式更为宽松，每秒可以获得 450 下请求，以每次请求获取最多 100 条推文来计算，每 15 分钟可以获得 45,000 条推文，这大概是前一种模式的 2.5 倍。<sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="参见 [How to use Twitter’s Search REST API most effectively](https://www.karambelkar.info/2015/01/how-to-use-twitters-search-rest-api-most-effectively./)。">[3]</span></a></sup> 但是，在某些方面 <strong>User authentication</strong>  也更有优势，<sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="可以参考官方文档 [Rate limits per window](https://developer.twitter.com/en/docs/basics/rate-limits)。">[4]</span></a></sup> 这就要根据自己研究需要进行切换了，这里我们采用 <strong>Application-only authentication</strong> 的认证模式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 导入用于获得推特准入许可的模块</span></div><div class="line"><span class="keyword">from</span> tweepy <span class="keyword">import</span> API</div><div class="line"><span class="keyword">from</span> tweepy <span class="keyword">import</span> OAuthHandler</div><div class="line"></div><div class="line"><span class="comment"># 定义两个函数</span></div><div class="line"></div><div class="line"><span class="comment"># 第一个是存入认证方式</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_twitter_auth</span><span class="params">()</span>:</span></div><div class="line">    consumer_key = <span class="string">'自己填'</span></div><div class="line">    consumer_secret = <span class="string">'自己填'</span></div><div class="line">    access_token = <span class="string">'自己填'</span></div><div class="line">    access_secret = <span class="string">'自己填'</span></div><div class="line"></div><div class="line"><span class="comment"># 若采用 User 的模式，则删除前面的“#”，并将之填在 APP 模式前</span></div><div class="line">    <span class="comment">#auth = OAuthHandler(consumer_key, consumer_secret)</span></div><div class="line">    <span class="comment">#auth.set_access_token(access_token, access_secret)</span></div><div class="line"></div><div class="line"><span class="comment"># 采用 APP 认证方式，提高可获取量</span></div><div class="line">    auth = AppAuthHandler(consumer_key, consumer_secret) </div><div class="line">    <span class="keyword">return</span> auth</div><div class="line"></div><div class="line"><span class="comment"># 第二个是与客户端通信</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_twitter_client</span><span class="params">()</span>:</span></div><div class="line">    auth = get_twitter_auth()</div><div class="line"><span class="comment"># 这里要注意设置代理的网址，因为科学上网的缘故，“proxy”填入代理ip</span></div><div class="line">    client = API(auth,proxy=<span class="string">"自己填"</span>,</div><div class="line">                 wait_on_rate_limit=<span class="keyword">True</span>, </div><div class="line">                 wait_on_rate_limit_notify=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">if</span> (<span class="keyword">not</span> API):</div><div class="line">        <span class="keyword">print</span> (<span class="string">"无法认证"</span>)</div><div class="line">        sys.exit(<span class="number">-1</span>)</div><div class="line">    <span class="keyword">return</span> client</div></pre></td></tr></table></figure><h2 id="简单测试"><a href="#简单测试" class="headerlink" title="简单测试"></a>简单测试</h2><p>前面的准备工作做好之后，我们可以通过运行一小段代码来检验是否连通：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">client = get_twitter_client()</div><div class="line"><span class="keyword">for</span> status <span class="keyword">in</span> Cursor(client.search, q=<span class="string">'china'</span>).items(<span class="number">10</span>):</div><div class="line">    print(status.text)</div></pre></td></tr></table></figure><p>如果成功连接了，这段代码会输出 10 条包含 “china” 的推文文本内容，比如下面这样的：</p><pre><code class="md hljs">RT @yicaichina: #China’s #Hebei Province, #LaureateScienceAlliance Discuss Setting Up Lab for #NobelWinners in #XionganNewArea https://t.co…RT @JackCanalha: Lugares mais populosos do mundo: China EUA  ÍndiaMinha casa de mosquitosRT @d_QfbKzDTe17: China van die aggressor nasie is indringer Suidsee omgewing sand.侵略国家のシナは南沙海域を侵略しています。アフリカーンス語 https://t.co/MThj4abonl@_____china_rock あと4㌢はきついから削れて？笑RT @yicaichina: #BAIC Motor Subsidiary to Build 3,000 #NEV Battery Swapping Stations in #China https://t.co/IJjCyEY3TQ https://t.co/qyImsHA…China van de agressor natie is zuiden zand Zeegebied invasie.侵略国家のシナは南沙海域を侵略しています。オランダ語 https://t.co/I3yC40kynFRT @yicaichina: #BAIC Motor Subsidiary to Build 3,000 #NEV Battery Swapping Stations in #China https://t.co/IJjCyEY3TQ https://t.co/qyImsHA…RT @yicaichina: #China’s Industrial Internet Platform #CASICloud Plans to Introduce New #Investors https://t.co/k3mW7S4I0b https://t.co/Sss…RT @LotusCreekKR: [이게 중국의 수준이다]국가(國歌) 에 대한 모독죄가 3년 징역형이라는 나라.  우리나라 공식행사에서 애국가 대신 다른 노래 부르는 분들 중에 친중파 참 많은데..... https://t.co/pyCzFupxSgSafe Flight @teacheryanyan wala akong Lunch buddy ng 4 days. Ingat kayo ni Tom and your sibs sa China! Lakas lang maka-conyo ng “sibs”</code></pre><h1 id="数据抓取"><a href="#数据抓取" class="headerlink" title="数据抓取"></a>数据抓取</h1><p>许可证程序已经做好了，接下来是爬取数据。从时间的角度，我们可以将数据分为<strong>静态数据</strong>，也就是已经存在的数据，或者说历史数据；还有一种是<strong>动态数据</strong>，就是实时跟踪推文的发布，同步抓取。受到网络环境的影响，动态数据的抓取难以测试，这里主要讲解静态数据的抓取。</p><h2 id="静态数据"><a href="#静态数据" class="headerlink" title="静态数据"></a>静态数据</h2><p>介绍一下 REST API<br>介绍一下 JSON 文件</p><h3 id="获取指定用户发布的信息"><a href="#获取指定用户发布的信息" class="headerlink" title="获取指定用户发布的信息"></a>获取指定用户发布的信息</h3><p>我们以《人民日报》的推特为例来说明如何抓取指定用户发布的推特信息。</p><p><img src="/images/15098659259951.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> tweepy <span class="keyword">import</span> Cursor</div><div class="line"></div><div class="line"><span class="comment"># 设置用户名，这里指的是 id 名，而不是昵称</span></div><div class="line">user = <span class="string">'PDChina'</span></div><div class="line"></div><div class="line"><span class="comment"># 将文件存储到以该用户命名的 jsonl 文件中，这里就是 user_timeline_huyong.jsonl</span></div><div class="line">fname = <span class="string">"user_timeline_%s.jsonl"</span> % user </div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'w'</span>) <span class="keyword">as</span> f: </div><div class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> Cursor(client.user_timeline, screen_name=user, count=<span class="number">200</span>).pages(<span class="number">16</span>):</div><div class="line">        <span class="keyword">for</span> status <span class="keyword">in</span> page:</div><div class="line">            f.write(json.dumps(status._json)+<span class="string">"\n"</span>)</div></pre></td></tr></table></figure><p>抓取到的内容存在一个 jsonl 文件中，因为我们设置了数值，最多 3200 条，也就不是抓取所有的发布。</p><h3 id="获取指定用户粉丝和关注的对象信息"><a href="#获取指定用户粉丝和关注的对象信息" class="headerlink" title="获取指定用户粉丝和关注的对象信息"></a>获取指定用户粉丝和关注的对象信息</h3><p>接下来我们继续爬取《人民日报》的粉丝和关注对象的信息，包括它的简介。为了防止出错，在每个抓取环节前都重新对抓取用户进行赋值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> math</div><div class="line"><span class="keyword">from</span> tweepy <span class="keyword">import</span> Cursor</div><div class="line"></div><div class="line"><span class="comment"># 设定了最大值</span></div><div class="line">MAX_FRIENDS = <span class="number">15000</span></div><div class="line">max_pages = math.ceil(MAX_FRIENDS / <span class="number">5000</span>)</div><div class="line"></div><div class="line"><span class="comment"># 以页数方式爬取</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">paginate</span><span class="params">(items, n)</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(items), n):</div><div class="line">        <span class="keyword">yield</span> items[i:i+n]   </div><div class="line"></div><div class="line"><span class="comment"># 创建用户文件夹，存放该用户相关文件</span></div><div class="line">dirname = <span class="string">"users/&#123;&#125;"</span>.format(user)</div><div class="line"><span class="keyword">try</span>:</div><div class="line">    os.makedirs(dirname, mode=<span class="number">0o755</span>, exist_ok=<span class="keyword">True</span>)</div><div class="line"><span class="keyword">except</span> OSError:</div><div class="line">    print(<span class="string">"文件夹 &#123;&#125; 已经存在"</span>.format(dirname))</div><div class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">    print(<span class="string">"在创建文件夹 &#123;&#125; 的时候出错了"</span>.format(dirname))</div><div class="line">    print(e)</div><div class="line">    sys.exit(<span class="number">1</span>)</div><div class="line">  </div><div class="line">user = <span class="string">'PDChina'</span>  </div><div class="line"><span class="comment"># 获得指定用户的粉丝信息</span></div><div class="line">fname = <span class="string">"users/&#123;&#125;/followers.jsonl"</span>.format(user)</div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">    <span class="keyword">for</span> followers <span class="keyword">in</span> Cursor(client.followers_ids, screen_name=user).pages(max_pages):</div><div class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> paginate(followers, <span class="number">100</span>):</div><div class="line">            users = client.lookup_users(user_ids=chunk)</div><div class="line">            <span class="keyword">for</span> user <span class="keyword">in</span> users:</div><div class="line">                f.write(json.dumps(user._json)+<span class="string">"\n"</span>)</div><div class="line">        <span class="keyword">if</span> len(followers) == <span class="number">5000</span>:</div><div class="line">            print(<span class="string">"正在抓取，休息，休息一下（60s）再继续～"</span>)</div><div class="line">            time.sleep(<span class="number">60</span>)</div><div class="line"></div><div class="line">user = <span class="string">'PDChina'</span>            </div><div class="line"><span class="comment"># 获取指定用户的关注信息</span></div><div class="line">fname = <span class="string">"users/&#123;&#125;/friends.jsonl"</span>.format(user)</div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">    <span class="keyword">for</span> friends <span class="keyword">in</span> Cursor(client.friends_ids, screen_name=user).pages(max_pages):</div><div class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> paginate(friends, <span class="number">100</span>):</div><div class="line">            users = client.lookup_users(user_ids=chunk)</div><div class="line">            <span class="keyword">for</span> user <span class="keyword">in</span> users:</div><div class="line">                f.write(json.dumps(user._json)+<span class="string">"\n"</span>)</div><div class="line">        <span class="keyword">if</span> len(friends) == <span class="number">5000</span>:</div><div class="line">            print(<span class="string">"正在抓取，休息，休息一下（60s）再继续～"</span>)</div><div class="line">            time.sleep(<span class="number">60</span>)</div><div class="line"></div><div class="line">user = <span class="string">'PDChina'</span></div><div class="line"><span class="comment"># 获取用户信息</span></div><div class="line">fname = <span class="string">"users/&#123;&#125;/user_profile.json"</span>.format(user)</div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">    profile = client.get_user(screen_name=user)</div><div class="line">    f.write(json.dumps(profile._json, indent=<span class="number">4</span>))</div></pre></td></tr></table></figure><p>根据抓取量大小情况，抓取时间会有所不同，抓取过程中会出现如下字样，请耐心等待：</p><pre><code class="md hljs">正在抓取，休息，休息一下（60s）再继续～正在抓取，休息，休息一下（60s）再继续～正在抓取，休息，休息一下（60s）再继续～</code></pre><p>程序结束后，可以在程序所在目录中看到多出一个“users”的文件夹，里面会有刚才抓取的“PDChina”，这个文件夹中的三个文件就是刚才获取的：</p><p><img src="/images/15098779145546.jpg" alt=""></p><h3 id="获取指定内容的搜索信息"><a href="#获取指定内容的搜索信息" class="headerlink" title="获取指定内容的搜索信息"></a>获取指定内容的搜索信息</h3><p>接下来，我们调用 Twitter 的搜索功能，以“china”为关键词进行检索，抓取 5000 条。这里要注意 Twitter 对搜索进行了限制，只能抓取最近7天内的内容，而不能在任意时间区间内进行检索。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 获取指定内容的搜索信息，并可以设定获取数值</span></div><div class="line"></div><div class="line"><span class="comment"># 要检索的内容</span></div><div class="line">searchQuery = <span class="string">'china'</span> </div><div class="line"><span class="comment"># 获取推文的最大值</span></div><div class="line">maxTweets = <span class="number">5000</span> </div><div class="line"><span class="comment"># 每次请求的最大值</span></div><div class="line">tweetsPerQry = <span class="number">100</span>  </div><div class="line"></div><div class="line">fname = <span class="string">"%s_search.jsonl"</span> % searchQuery</div><div class="line">sinceId = <span class="keyword">None</span></div><div class="line">max_id = <span class="number">-1</span></div><div class="line"></div><div class="line">tweetCount = <span class="number">0</span></div><div class="line"></div><div class="line">print(<span class="string">"最多下载 &#123;0&#125; 条推特"</span>.format(maxTweets))</div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">    <span class="keyword">while</span> tweetCount &lt; maxTweets:</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="keyword">if</span> (max_id &lt;= <span class="number">0</span>):</div><div class="line">                <span class="keyword">if</span> (<span class="keyword">not</span> sinceId):</div><div class="line">                    new_tweets = client.search(q=searchQuery, </div><div class="line">                                               count=tweetsPerQry)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    new_tweets = client.search(q=searchQuery, </div><div class="line">                                               count=tweetsPerQry, </div><div class="line">                                               since_id=sinceId)</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                <span class="keyword">if</span> (<span class="keyword">not</span> sinceId):</div><div class="line">                    new_tweets = client.search(q=searchQuery, </div><div class="line">                                               count=tweetsPerQry,</div><div class="line">                                               max_id=str(max_id - <span class="number">1</span>))</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    new_tweets = client.search(q=searchQuery, </div><div class="line">                                               count=tweetsPerQry,</div><div class="line">                                               max_id=str(max_id - <span class="number">1</span>),</div><div class="line">                                               since_id=sinceId)</div><div class="line">            <span class="keyword">if</span> <span class="keyword">not</span> new_tweets:</div><div class="line">                print(<span class="string">"没有发现更多的推特"</span>)</div><div class="line">                <span class="keyword">break</span></div><div class="line">            <span class="keyword">for</span> tweet <span class="keyword">in</span> new_tweets:</div><div class="line">                f.write(json.dumps(tweet._json) +<span class="string">'\n'</span>)</div><div class="line">            tweetCount += len(new_tweets)</div><div class="line">            print(<span class="string">"已下载 &#123;0&#125; 条推特"</span>.format(tweetCount))</div><div class="line">            max_id = new_tweets[<span class="number">-1</span>].id</div><div class="line">        <span class="keyword">except</span> tweepy.TweepError <span class="keyword">as</span> e:</div><div class="line">            print(<span class="string">"出错了 : "</span> + str(e))</div><div class="line">            <span class="keyword">break</span></div><div class="line"></div><div class="line"><span class="keyword">print</span> (<span class="string">"共下载了 &#123;0&#125; 条推特, 已存入 &#123;1&#125;"</span>.format(tweetCount, fname))</div></pre></td></tr></table></figure><p>程序开始跑起来的时候，可以看到结果界面不断更新抓取的推特数量，最后我们可以看到总共抓取的推特数量：</p><pre><code class="md hljs">最多下载 5000 条推特已下载 100 条推特已下载 200 条推特已下载 300 条推特已下载 400 条推特已下载 500 条推特已下载 600 条推特已下载 700 条推特已下载 800 条推特已下载 898 条推特已下载 996 条推特已下载 1096 条推特已下载 1196 条推特已下载 1296 条推特已下载 1387 条推特已下载 1487 条推特已下载 1587 条推特已下载 1687 条推特已下载 1780 条推特已下载 1880 条推特已下载 1980 条推特已下载 2079 条推特已下载 2179 条推特已下载 2279 条推特已下载 2379 条推特已下载 2479 条推特已下载 2535 条推特已下载 2577 条推特已下载 2677 条推特已下载 2777 条推特已下载 2877 条推特已下载 2977 条推特已下载 3074 条推特已下载 3171 条推特已下载 3271 条推特已下载 3367 条推特已下载 3467 条推特已下载 3567 条推特已下载 3667 条推特已下载 3762 条推特已下载 3862 条推特已下载 3962 条推特已下载 4062 条推特已下载 4158 条推特已下载 4258 条推特已下载 4358 条推特已下载 4458 条推特已下载 4558 条推特已下载 4645 条推特已下载 4745 条推特已下载 4845 条推特已下载 4945 条推特已下载 5045 条推特共下载了 5045 条推特, 已存入 china_search.jsonl</code></pre><h2 id="动态数据"><a href="#动态数据" class="headerlink" title="动态数据"></a>动态数据</h2><h3 id="指定标签和内容的信息流"><a href="#指定标签和内容的信息流" class="headerlink" title="指定标签和内容的信息流"></a>指定标签和内容的信息流</h3><p>因网络环境无法调试，此处省略。</p><h1 id="数据处理和分析"><a href="#数据处理和分析" class="headerlink" title="数据处理和分析"></a>数据处理和分析</h1><p>刚才的抓取获得了三种类型的文件，第一种是用户发布的信息流，我们命名为 <code>user_timelin_PDChina.jsonl</code> ；第二种是用户的粉丝、关注和个人的用户信息，我们把这三个文件放在了一个 “users” 类别的文件夹中，里面还有个以该用户命名的 “PDChina” 文件夹，存放了我们抓取到的 followers.jsonl 、 friends.jsonl 和 user_profile.json 这三个文件；第三种是检索获取的推文信息，我们将其命名为 “china_search.jsonl”。在对数据处理的时候，依据处理的目的，选择不同的文件。利用编辑器可以打开 jsonl 的文件，比如用户发布的信息流文件，打开后我们可以看到密密麻麻的数据，因此，在处理之前我们需要先理解文件内部的结构，这样我们才能清除结构，获取我们需要的信息。</p><p><img src="/images/15098670766922.jpg" alt=""></p><h2 id="推文的数据结构"><a href="#推文的数据结构" class="headerlink" title="推文的数据结构"></a>推文的数据结构</h2><p>抓取的信息都存放在了 JavaScript Object Notation (JSON)  文件中，在用编辑器打开的文件中我们可以看到它的主体结构是这样的：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"tweet"</span>: &#123;</div><div class="line">    <span class="attr">"user"</span>: &#123;</div><div class="line">      </div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"place"</span>: &#123;</div><div class="line">      </div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"entities"</span>: &#123;</div><div class="line">      </div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"extended_entities"</span>: &#123;</div><div class="line">      </div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>从这里我们可以发现这个数据结构有一个主对象： <code>tweet</code>（推文信息）；有四个子对象：<code>user</code>（发布者信息），<code>place</code>（地理信息），<code>entities</code>（推文中的非文本信息），<code>extended_entities</code>（推文外的非文本信息）。这五大对象里面还包含各种字段，这些字段有不同的变量类型，可能是数值、字符串或者布尔值等，也可能存放的不只是文本，可以是图片或音频等媒体的链接地址。这样的数据构成可以说就是我们通常所言的“非结构化数据”了，虽然看起来是一种很“结构”的数据。</p><p>转发的推文实际上就是在<code>user</code>后面加了一个转推对象 <code>retweeted_status</code>，里面的结构还是推文的结构，也就是一种嵌套了：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"tweet"</span>: &#123;</div><div class="line">    <span class="attr">"user"</span>: &#123;</div><div class="line">      </div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"retweeted_status"</span>: &#123;</div><div class="line">      <span class="attr">"tweet"</span>: &#123;</div><div class="line">        <span class="attr">"user"</span>: &#123;</div><div class="line">          </div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"place"</span>: &#123;</div><div class="line">          </div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"entities"</span>: &#123;</div><div class="line">          </div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"extended_entities"</span>: &#123;</div><div class="line">          </div><div class="line">        &#125;</div><div class="line">      &#125;,</div><div class="line">      </div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"place"</span>: &#123;</div><div class="line">      </div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"entities"</span>: &#123;</div><div class="line">      </div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"extended_entities"</span>: &#123;</div><div class="line">      </div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="字段说明"><a href="#字段说明" class="headerlink" title="字段说明"></a>字段说明</h2><p>字段里面的信息才是我们需要获取的，因此在能清楚数据的结构层次之后，我们应该了解哪些字段的信息是我们需要抓取的。官方文档里提供了五个对象字段（<code>tweet</code>，<code>user</code>，<code>entities</code>， <code>extended entities</code>，<code>geo</code>）的字段介绍，这里主要介绍抓取常常要处理的 <code>Tweet Object</code> 及其子对象 <code>User Object</code>，其他可参阅官方文档。</p><h3 id="Tweet-object"><a href="#Tweet-object" class="headerlink" title="Tweet object"></a>Tweet object</h3><p>这种数据结构层面的数据和我们直观所见的有很大的不同，数据结构是对存放的信息进行了归类，有些信息并不能体现在我们所见的推文中，但是可见的也是必然有的，不可见的也常常缺失，下面这个是我对官方提供的样例所做的注解：</p><p><img src="/images/15099378811861.jpg" alt="tweet object"></p><p>再对比下面的字段就可以发现，有很多隐性的内容存放在了数据结构之中。</p><table><thead><tr><th>返回字段</th><th>字段说明</th><th>字段类型</th></tr></thead><tbody><tr><td>coordinates</td><td>地理坐标</td><td>Coordinates</td></tr><tr><td>created_at</td><td>推文创建时间</td><td>String</td></tr><tr><td>entities</td><td>推文内非文本信息</td><td>Entities</td></tr><tr><td>favorite_count</td><td>推文点赞数</td><td>Integer</td></tr><tr><td>favorited</td><td>是否认证人点赞了</td><td>Boolean</td></tr><tr><td>geo</td><td>地理坐标</td><td>Object</td></tr><tr><td>id</td><td>推文唯一识别号</td><td>Int64</td></tr><tr><td>id_str</td><td>推文唯一识别号</td><td>String</td></tr><tr><td>in_reply_to_status_id</td><td>这条回复的id</td><td>Int64</td></tr><tr><td>in_reply_to_status_id_str</td><td>这条回复的id</td><td>String</td></tr><tr><td>in_reply_to_user_id</td><td>回复对象的id</td><td>Int64</td></tr><tr><td>in_reply_to_screen_name</td><td>回复对象的昵称</td><td>String</td></tr><tr><td>in_reply_to_user_id_str</td><td>回复对象的id</td><td>String</td></tr><tr><td>is_quote_status</td><td>是否为引用的推文</td><td>Boolean</td></tr><tr><td>lang</td><td>推文的语言</td><td>String</td></tr><tr><td>place</td><td>发推地点</td><td>Places</td></tr><tr><td>possibly_sensitive</td><td>敏感内容可能性</td><td>Boolean</td></tr><tr><td>retweet_count</td><td>转发数</td><td>Int</td></tr><tr><td>retweeted</td><td>是否被认证用户转发</td><td>Boolean</td></tr><tr><td>source</td><td>发推设备</td><td>String</td></tr><tr><td>text</td><td>推文文本</td><td>String</td></tr><tr><td>truncated</td><td>推文是否因超过字数删减</td><td>Boolean</td></tr><tr><td>user</td><td>发推者的用户信息</td><td>User object</td></tr><tr><td>quoted_status_id</td><td>引用推文的id</td><td>Int64</td></tr><tr><td>quoted_status_id_str</td><td>引用推文的</td><td>String</td></tr><tr><td>quoted_status</td><td>引用推文区</td><td>Tweet</td></tr><tr><td>retweeted_status</td><td>转发推文区</td><td>Tweet</td></tr><tr><td>quote_count</td><td>引用推文计数</td><td>Integer</td></tr><tr><td>reply_count</td><td>回复计数</td><td>Int</td></tr><tr><td>extended_entities</td><td>推文外非文本信息</td><td>Extended Entities</td></tr><tr><td>filter_level</td><td>过滤等级</td><td>String</td></tr><tr><td>matching_rules</td><td>用于过滤</td><td>Array of Rule Objects</td></tr></tbody></table><h3 id="User-object"><a href="#User-object" class="headerlink" title="User object"></a>User object</h3><p>同样在 Tweet 的子对象 User 中，有些字段不是必然有的，有些字段是可变的，因此我们所见的也不完全是数据结构中所含有的。</p><p><img src="/images/15099422654271.jpg" alt="user object"></p><table><thead><tr><th>返回字段</th><th>字段说明</th><th>字段类型</th></tr></thead><tbody><tr><td>id</td><td>用户的id</td><td>Int64</td></tr><tr><td>id_str</td><td>用户的id</td><td>String</td></tr><tr><td>name</td><td>用户昵称（可改）</td><td>String</td></tr><tr><td>screen_name</td><td>用户识别名（不可改）</td><td>String</td></tr><tr><td>location</td><td>用户设定的简介地点</td><td>String</td></tr><tr><td>url</td><td>用户提供的主页网址</td><td>String</td></tr><tr><td>description</td><td>用户的简介</td><td>String</td></tr><tr><td>derived</td><td>用户的一些元数据</td><td>Arrays of Enrichment Objects</td></tr><tr><td>protected</td><td>推文是否受保护</td><td>Boolean</td></tr><tr><td>verified</td><td>是否为认证用户</td><td>Boolean</td></tr><tr><td>followers_count</td><td>粉丝数</td><td>Int</td></tr><tr><td>friends_count</td><td>关注数</td><td>Int</td></tr><tr><td>listed_count</td><td>该用户属于公开列表的数量</td><td>Int</td></tr><tr><td>favourites_count</td><td>用户在使用期间的点赞数</td><td>Int</td></tr><tr><td>statuses_count</td><td>用户发推数量，包括转发</td><td>Int</td></tr><tr><td>created_at</td><td>用户账号创建时间</td><td>String</td></tr><tr><td>utc_offset</td><td>The offset from GMT/UTC in seconds</td><td>Int</td></tr><tr><td>time_zone</td><td>用户设定的时区</td><td>String</td></tr><tr><td>geo_enabled</td><td>是否开启地理位置</td><td>Boolean</td></tr><tr><td>lang</td><td>用户使用语言</td><td>String</td></tr><tr><td>contributors_enabled</td><td>是否开启共同创作者</td><td>Boolean</td></tr><tr><td>profile_background_color</td><td>用户使用的背景色</td><td>String</td></tr><tr><td>profile_background_image_url</td><td>用户使用的背景图片的地址</td><td>String</td></tr><tr><td>profile_background_image_url_https</td><td>用户使用的背景图片的地址 https</td><td>String</td></tr><tr><td>profile_background_tile</td><td>是否显示背景图片名称</td><td>Boolean</td></tr><tr><td>profile_banner_url</td><td>用户横幅网址</td><td>String</td></tr><tr><td>profile_image_url</td><td>用户头像网址</td><td>String</td></tr><tr><td>profile_image_url_https</td><td>用户头像网址 https</td><td>String</td></tr><tr><td>profile_link_color</td><td>用户显示链接的颜色</td><td>String</td></tr><tr><td>profile_sidebar_border_color</td><td>用户边栏线颜色</td><td>String</td></tr><tr><td>profile_sidebar_fill_color</td><td>用户边栏填充颜色</td><td>String</td></tr><tr><td>profile_text_color</td><td>用户文本颜色</td><td>String</td></tr><tr><td>profile_use_background_image</td><td>用户是否使用背景图片</td><td>Boolean</td></tr><tr><td>default_profile</td><td>用户是否切换用户主题</td><td>Boolean</td></tr><tr><td>default_profile_image</td><td>用户是否上传了自己的头像</td><td>Boolean</td></tr><tr><td>withheld_in_countries</td><td>隐藏地区</td><td>String</td></tr><tr><td>withheld_scope</td><td>隐藏范围</td><td>String</td></tr><tr><td>is_translator</td><td>用户是否加入译者计划</td><td>Boolean</td></tr></tbody></table><h3 id="其他对象"><a href="#其他对象" class="headerlink" title="其他对象"></a>其他对象</h3><ul><li><a href="https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/entities-object1" target="_blank" rel="external">Entities object</a></li><li><a href="https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/extended-entities-object" target="_blank" rel="external">Extend Entities object</a></li><li><a href="https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/geo-objects" target="_blank" rel="external">Geo object</a></li></ul><h2 id="指定字段的抓取方法"><a href="#指定字段的抓取方法" class="headerlink" title="指定字段的抓取方法"></a>指定字段的抓取方法</h2><p>通过上面的数据收集，我们可以获得五个文件，分别是：指定用户的推文、粉丝信息、关注信息、用户信息和指定内容的检索信息。实际上是两类，一类是推文整体，一类是局部的用户对象（user object）。前面我们已经熟悉了推文的字段，还重点看了下用户的字段，这些字段其实就存在数据结构之中，也就是说信息被结构所掩盖了，我们恰恰需要清除结构，提取我们需要的重要信息，那么，我们是否能有一种方法任意地提取指定的字段信息呢？下面我们以提取 <code>#标签</code> 为例来发展一套普遍的提取方法。</p><h3 id="标签处理（hashtags）"><a href="#标签处理（hashtags）" class="headerlink" title="标签处理（hashtags）"></a>标签处理（hashtags）</h3><p>为获取 <code>#标签</code>（hashtags），我们首先要分析下它存在什么地方。</p><p>第一个层级是在 <code>tweet</code> 中的 <code>entities</code> 里：</p><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">"entities": &#123;</div><div class="line">    "hashtags": [</div><div class="line">    ],</div><div class="line">    "urls": [</div><div class="line">    ],</div><div class="line">    "user_mentions": [</div><div class="line">    ],</div><div class="line">    "symbols": [</div><div class="line">    ]</div><div class="line">  &#125;</div></pre></td></tr></table></figure><p>第二个层级是在<code>entities</code>中的<code>hashtags</code>里：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"hashtags"</span>: [</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"indices"</span>: [</div><div class="line">        <span class="number">32</span>,</div><div class="line">        <span class="number">38</span></div><div class="line">      ],</div><div class="line">      <span class="attr">"text"</span>: <span class="string">"nodejs"</span></div><div class="line">    &#125;</div><div class="line">  ]</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>在 <code>hashtags</code> 里有两个字段，但可以有多个存在，也就是说可以有很多个标签，它们都在里面，且各自包含下面这样的字段类型：</p><table><thead><tr><th>返回字段</th><th>字段说明</th><th>字段类型</th></tr></thead><tbody><tr><td>indices</td><td>索引，第一个数字是这个标签在推特文本的位置，两个数值相减再加上“#”就是字符长度</td><td>Array of Int</td></tr><tr><td>text</td><td>标签文本内容</td><td>String</td></tr></tbody></table><p>这样我们实际需要的就是 <code>text</code> 里面的内容了。</p><h4 id="定义获取“标签”字段的方法"><a href="#定义获取“标签”字段的方法" class="headerlink" title="定义获取“标签”字段的方法"></a>定义获取“标签”字段的方法</h4><p>上面的数据结构实际上就是 Python 中的字典结构，我们就可以利用 dict 中的 get 方法来获取指定字段：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_hashtags</span><span class="params">(tweet)</span>:</span></div><div class="line">    entities = tweet.get(<span class="string">'entities'</span>, &#123;&#125;)</div><div class="line">    hashtags = entities.get(<span class="string">'hashtags'</span>, [])</div><div class="line">    <span class="keyword">return</span> [tag[<span class="string">'text'</span>].lower() <span class="keyword">for</span> tag <span class="keyword">in</span> hashtags]</div></pre></td></tr></table></figure><p>指定字段提取方法就是仿照上面的代码处理方式，首先明确该字段在数据结构中的位置，然后运用字典的提取方法获取字段的内容。</p><h4 id="计算标签频数"><a href="#计算标签频数" class="headerlink" title="计算标签频数"></a>计算标签频数</h4><p>以一个简单的例子来测试下，将 <code>fname</code> 这个变量设置为获取的指定用户发布信息的文件名，这里是<strong>user_timeline_PDChina.jsonl</strong>  ，然后运行程序获取推文的标签，并计算标签的频数，由多到少排列前20个：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line">fname = <span class="string">'user_timeline_PDChina.jsonl'</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line"><span class="comment"># 引入一个计数的函数</span></div><div class="line">    hashtags = Counter() </div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">        tweet = json.loads(line)</div><div class="line">        hashtags_in_tweet = get_hashtags(tweet)</div><div class="line">        hashtags.update(hashtags_in_tweet)</div><div class="line"></div><div class="line"><span class="comment"># 提取前二十个        </span></div><div class="line">    <span class="keyword">for</span> tag, count <span class="keyword">in</span> hashtags.most_common(<span class="number">20</span>): </div><div class="line">        print(<span class="string">"&#123;&#125;: &#123;&#125;"</span>.format(tag, count))</div></pre></td></tr></table></figure><p>下面就是输出结果，这里提取了《人民日报》推特所发布推文中含有的标签前20名：</p><pre><code class="md hljs">breaking: 142dprk: 78xijinping: 64china: 60earthquake: 58update: 4519thcpc: 45brics: 39peoplesdailycomments: 32russia: 23beijing: 23india: 21panda: 20southchinasea: 19brics2017: 18beltandroad: 17shanghai: 15sichuan: 15japan: 15voiceofchina: 14</code></pre><p>从话题标签中大致可以看到，《人民日报》在对外宣传中除了突发新闻的报道和领导人的重要新闻外，熊猫也是一张显耀的中国名片。</p><h4 id="统计指定发布的标签情况"><a href="#统计指定发布的标签情况" class="headerlink" title="统计指定发布的标签情况"></a>统计指定发布的标签情况</h4><p>接下来我们统计下《人民日报》发布的推文所带标签的情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</div><div class="line"></div><div class="line">fname = <span class="string">'user_timeline_PDChina.jsonl'</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">    hashtag_count = defaultdict(int)</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">        tweet = json.loads(line)</div><div class="line">        hashtags_in_tweet = get_hashtags(tweet)</div><div class="line">        n_of_hashtags = len(hashtags_in_tweet)</div><div class="line">        hashtag_count[n_of_hashtags] += <span class="number">1</span></div><div class="line"></div><div class="line">    tweets_with_hashtags = sum([count <span class="keyword">for</span> n_of_tags, count <span class="keyword">in</span> hashtag_count.items() <span class="keyword">if</span> n_of_tags &gt; <span class="number">0</span>])</div><div class="line">    tweets_no_hashtags = hashtag_count[<span class="number">0</span>]</div><div class="line">    tweets_total = tweets_no_hashtags + tweets_with_hashtags</div><div class="line">    tweets_with_hashtags_percent = <span class="string">"%.2f"</span> % (tweets_with_hashtags / tweets_total * <span class="number">100</span>)</div><div class="line">    tweets_no_hashtags_percent = <span class="string">"%.2f"</span> % (tweets_no_hashtags / tweets_total * <span class="number">100</span>)</div><div class="line">    print(<span class="string">"共有 &#123;&#125; 条推文没有话题标签 (占总量的 &#123;&#125;%)"</span>.format(tweets_no_hashtags, tweets_no_hashtags_percent))</div><div class="line">    print(<span class="string">"共有 &#123;&#125; 条推文至少有一个话题标签 (占总量的 &#123;&#125;%)"</span>.format(tweets_with_hashtags, tweets_with_hashtags_percent))</div><div class="line"></div><div class="line">    <span class="keyword">for</span> tag_count, tweet_count <span class="keyword">in</span> hashtag_count.items():</div><div class="line">        <span class="keyword">if</span> tag_count &gt; <span class="number">0</span>:</div><div class="line">            percent_total = <span class="string">"%.2f"</span> % (tweet_count / tweets_total * <span class="number">100</span>)</div><div class="line">            percent_elite = <span class="string">"%.2f"</span> % (tweet_count / tweets_with_hashtags * <span class="number">100</span>)</div><div class="line">            print(<span class="string">"共有 &#123;&#125; 条推文带有 &#123;&#125; 个话题标签 (占总量的 &#123;&#125;% , 占标签推文的 &#123;&#125;% )"</span>.format(tweet_count,</div><div class="line">                                                                             tag_count,</div><div class="line">                                                                             percent_total,</div><div class="line">                                                                             percent_elite))</div></pre></td></tr></table></figure><p>输出的结果可能是这样：</p><pre><code class="md hljs">共有 2014 条推文没有话题标签 (占总量的 62.94%)共有 1186 条推文至少有一个话题标签 (占总量的 37.06%)共有 855 条推文带有 1 个话题标签 (占总量的 26.72% , 占标签推文的 72.09% )共有 254 条推文带有 2 个话题标签 (占总量的 7.94% , 占标签推文的 21.42% )共有 69 条推文带有 3 个话题标签 (占总量的 2.16% , 占标签推文的 5.82% )共有 8 条推文带有 4 个话题标签 (占总量的 0.25% , 占标签推文的 0.67% )</code></pre><h2 id="方法举例"><a href="#方法举例" class="headerlink" title="方法举例"></a>方法举例</h2><p>下面这里提供一些数据处理的方法。</p><h3 id="提及处理（user-mentions）"><a href="#提及处理（user-mentions）" class="headerlink" title="提及处理（user_mentions）"></a>提及处理（user_mentions）</h3><p>“提及”也就是推特或微博中的“@”。</p><h4 id="定义获取“提及”字段的方法"><a href="#定义获取“提及”字段的方法" class="headerlink" title="定义获取“提及”字段的方法"></a>定义获取“提及”字段的方法</h4><p>这个方法也跟标签的处理一样，利用字典的 get 方法抓取指定字段的信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mentions</span><span class="params">(tweet)</span>:</span></div><div class="line">    entities = tweet.get(<span class="string">'entities'</span>, &#123;&#125;)</div><div class="line">    hashtags = entities.get(<span class="string">'user_mentions'</span>, [])</div><div class="line">    <span class="keyword">return</span> [tag[<span class="string">'screen_name'</span>] <span class="keyword">for</span> tag <span class="keyword">in</span> hashtags]</div></pre></td></tr></table></figure><h4 id="计算提及的频数"><a href="#计算提及的频数" class="headerlink" title="计算提及的频数"></a>计算提及的频数</h4><p>我们来看下《人民日报》@人的情况，也是获取前20个及计算频数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"><span class="keyword">import</span> json</div><div class="line"></div><div class="line">fname = <span class="string">'user_timeline_huyong.jsonl'</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">    users = Counter()</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">        tweet = json.loads(line)</div><div class="line">        mentions_in_tweet = get_mentions(tweet)</div><div class="line">        users.update(mentions_in_tweet)</div><div class="line">    <span class="keyword">for</span> user, count <span class="keyword">in</span> users.most_common(<span class="number">20</span>):</div><div class="line">        print(<span class="string">"&#123;&#125;: &#123;&#125;"</span>.format(user, count))</div></pre></td></tr></table></figure><p>以下是输出结果：</p><pre><code class="md hljs">realDonaldTrump: 55UN: 20Tsinghua_Uni: 8MedvedevRussiaE: 6Kunshan_China: 6WhiteHouse: 5UNESCO: 5leehsienloong: 4EPN: 4USNavy: 4narendramodi: 4MichelTemer: 4KremlinRussia_E: 4loveJiangsu: 3ASEAN: 3TexasTech: 3AbeShinzo: 3PDChina: 3iaeaorg: 3NASA: 2</code></pre><p>有趣的是第一个竟然是美国总统，而且国外人物或组织较多。</p><h3 id="推文文本分析（text）"><a href="#推文文本分析（text）" class="headerlink" title="推文文本分析（text）"></a>推文文本分析（text）</h3><p>这里的文本分析实际上就是对推文文本进行分词处理，并计算词频。</p><h4 id="分词处理和缩写恢复"><a href="#分词处理和缩写恢复" class="headerlink" title="分词处理和缩写恢复"></a>分词处理和缩写恢复</h4><p>首先我们来设置两个函数，一个是处理分词，一个是处理英文中的缩写。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> TweetTokenizer</div><div class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(text, tokenizer=TweetTokenizer<span class="params">()</span>, stopwords=[])</span>:</span></div><div class="line">    text = text.lower()</div><div class="line">    tokens = tokenizer.tokenize(text)</div><div class="line">    tokens = normalize_contractions(tokens)</div><div class="line">    <span class="keyword">return</span> [tok <span class="keyword">for</span> tok <span class="keyword">in</span> tokens <span class="keyword">if</span> tok <span class="keyword">not</span> <span class="keyword">in</span> stopwords <span class="keyword">and</span> <span class="keyword">not</span> tok.isdigit()]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_contractions</span><span class="params">(tokens)</span>:</span></div><div class="line">    token_map = &#123;</div><div class="line">        <span class="string">"i'm"</span>: <span class="string">"i am"</span>,</div><div class="line">        <span class="string">"you're"</span>: <span class="string">"you are"</span>,</div><div class="line">        <span class="string">"it's"</span>: <span class="string">"it is"</span>,</div><div class="line">        <span class="string">"we're"</span>: <span class="string">"we are"</span>,</div><div class="line">        <span class="string">"we'll"</span>: <span class="string">"we will"</span>,</div><div class="line">        <span class="string">"china's"</span>: <span class="string">"china is"</span>,</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">for</span> tok <span class="keyword">in</span> tokens:</div><div class="line">        <span class="keyword">if</span> tok <span class="keyword">in</span> token_map.keys():</div><div class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> token_map[tok].split():</div><div class="line">                <span class="keyword">yield</span> item</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">yield</span> tok</div></pre></td></tr></table></figure><h4 id="计算推文词频"><a href="#计算推文词频" class="headerlink" title="计算推文词频"></a>计算推文词频</h4><p>在运行这段代码后，可能发现输出结果有较多标点或者缩写没有区分开来，这里就要对上面缩写区分函数和下面代码中处理标点的命令进行修改，添加需要去除的东西，然后我们再运行程序获取前 30 个单词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> string</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line"></div><div class="line">tweet_tokenizer = TweetTokenizer()</div><div class="line">punct = list(string.punctuation+<span class="string">'…'</span>+<span class="string">'“'</span>+<span class="string">'’'</span>)</div><div class="line">stopword_list = stopwords.words(<span class="string">'english'</span>) + punct + [<span class="string">'rt'</span>, <span class="string">'via'</span>]</div><div class="line"></div><div class="line">fname = <span class="string">'user_timeline_PDChina.jsonl'</span></div><div class="line"></div><div class="line">tf = Counter()</div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">        tweet = json.loads(line)</div><div class="line">        tokens = process(text=tweet.get(<span class="string">'text'</span>, <span class="string">''</span>),</div><div class="line">                         tokenizer=tweet_tokenizer,</div><div class="line">                         stopwords=stopword_list)</div><div class="line">        tf.update(tokens)</div><div class="line">    <span class="keyword">for</span> tag, count <span class="keyword">in</span> tf.most_common(<span class="number">30</span>):</div><div class="line">        print(<span class="string">"&#123;&#125;: &#123;&#125;"</span>.format(tag, count))</div></pre></td></tr></table></figure><p>以下是输出结果：</p><pre><code class="md hljs">china: 1354chinese: 483us: 227#breaking: 142president: 140new: 136national: 134province: 124first: 113people: 106w: 89says: 89xi: 85killed: 81world: 80sw: 75years: 75injured: 74city: 71#dprk: 71central: 69police: 67military: 66man: 65south: 63#xijinping: 63least: 61year: 60#earthquake: 58beijing: 57</code></pre><h3 id="用户粉丝和关注概况"><a href="#用户粉丝和关注概况" class="headerlink" title="用户粉丝和关注概况"></a>用户粉丝和关注概况</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">screen_name = <span class="string">'PDChina'</span></div><div class="line">followers_file = <span class="string">'users/&#123;&#125;/followers.jsonl'</span>.format(screen_name)</div><div class="line">friends_file = <span class="string">'users/&#123;&#125;/friends.jsonl'</span>.format(screen_name)</div><div class="line">profile_file = <span class="string">'users/&#123;&#125;/user_profile.json'</span>.format(screen_name)</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(followers_file) <span class="keyword">as</span> f1, open(friends_file) <span class="keyword">as</span> f2, open(profile_file) <span class="keyword">as</span> f:</div><div class="line">    </div><div class="line">    user_profile = json.load(f)</div><div class="line">    followers = []</div><div class="line">    friends = []</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f1:</div><div class="line">        profile = json.loads(line)</div><div class="line">        followers.append(profile[<span class="string">'screen_name'</span>])</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f2:</div><div class="line">        profile = json.loads(line)</div><div class="line">        friends.append(profile[<span class="string">'screen_name'</span>])</div><div class="line">    followers = np.array(followers)</div><div class="line">    friends = np.array(friends)</div><div class="line"></div><div class="line">    mutual_friends = np.intersect1d(friends, followers, assume_unique=<span class="keyword">True</span>)</div><div class="line">    followers_not_following = np.setdiff1d(followers, friends, assume_unique=<span class="keyword">True</span>)</div><div class="line">    friends_not_following = np.setdiff1d(friends, followers, assume_unique=<span class="keyword">True</span>)</div><div class="line">    </div><div class="line">    user_followers = user_profile[<span class="string">'followers_count'</span>]</div><div class="line">    user_friends = user_profile[<span class="string">'friends_count'</span>]</div><div class="line">    user_name = user_profile[<span class="string">'name'</span>]</div><div class="line">    user_statuses = user_profile[<span class="string">'statuses_count'</span>]</div><div class="line">    user_time = pd.to_datetime([user_profile[<span class="string">'created_at'</span>]][<span class="number">0</span>])</div><div class="line">    user_description = user_profile[<span class="string">'description'</span>]</div><div class="line">    </div><div class="line">    print(<span class="string">"*****【用户信息摘要】*****"</span>)</div><div class="line">    </div><div class="line">    print(<span class="string">"----- 用户的实际情况 -----"</span>)</div><div class="line">    print(<span class="string">"用户 &#123;&#125; 的昵称为：&#123;&#125; "</span>.format(screen_name, user_name))</div><div class="line">    print(<span class="string">"该帐号创建于：&#123;&#125; "</span>.format(user_time))</div><div class="line">    print(<span class="string">"共有 &#123;&#125; 个粉丝 "</span>.format(user_followers))</div><div class="line">    print(<span class="string">"共有 &#123;&#125; 个关注 "</span>.format(user_friends))</div><div class="line">    print(<span class="string">"共发 &#123;&#125; 条推文 "</span>.format(user_statuses))</div><div class="line">    print(<span class="string">'该用户的介绍：&#123;&#125;'</span>.format(user_description))</div><div class="line">    </div><div class="line">    print(<span class="string">"----- 所抓信息的统计结果 -----"</span>)</div><div class="line">    print(<span class="string">"抓取到该用户的 &#123;&#125; 个粉丝"</span>.format( len(followers)))</div><div class="line">    print(<span class="string">"抓取到该用户的 &#123;&#125; 个关注"</span>.format(len(friends)))</div><div class="line">    print(<span class="string">"该用户有 &#123;&#125; 个共同好友"</span>.format(len(mutual_friends)))</div><div class="line">    print(<span class="string">"其中有 &#123;&#125; 关注对象没有关注该用户 "</span>.format(len(friends_not_following)))</div><div class="line">    print(<span class="string">"其中有 &#123;&#125; 粉丝没有被该用户关注"</span>.format(len(followers_not_following)))</div></pre></td></tr></table></figure><pre><code class="md hljs">*****【用户信息摘要】*****----- 用户的实际情况 -----用户 PDChina 的昵称为：People's Daily,China 该帐号创建于：2011-05-23 15:00:26 共有 4158120 个粉丝 共有 5331 个关注 共发 55397 条推文 该用户的介绍：The largest newspaper group in China; Timely updates https://t.co/GjIOtXvfA2 https://t.co/nCvfm8gTgr----- 所抓信息的统计结果 -----抓取到该用户的 15000 个粉丝抓取到该用户的 5331 个关注该用户有 0 个共同好友其中有 5331 关注对象没有关注该用户 其中有 15000 粉丝没有被该用户关注</code></pre><h3 id="用户影响力比较分析"><a href="#用户影响力比较分析" class="headerlink" title="用户影响力比较分析"></a>用户影响力比较分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> json</div><div class="line"></div><div class="line"></div><div class="line">screen_name1 = <span class="string">'huyong'</span></div><div class="line">screen_name2 = <span class="string">'bbcchinese'</span></div><div class="line"></div><div class="line">followers_file1 = <span class="string">'users/&#123;&#125;/followers.jsonl'</span>.format(screen_name1)</div><div class="line">followers_file2 = <span class="string">'users/&#123;&#125;/followers.jsonl'</span>.format(screen_name2)</div><div class="line"><span class="keyword">with</span> open(followers_file1) <span class="keyword">as</span> f1, open(followers_file2) <span class="keyword">as</span> f2:</div><div class="line">    reach1 = []</div><div class="line">    reach2 = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f1:</div><div class="line">        profile = json.loads(line)</div><div class="line">        reach1.append((profile[<span class="string">'screen_name'</span>], profile[<span class="string">'followers_count'</span>]))</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f2:</div><div class="line">        profile = json.loads(line)</div><div class="line">        reach2.append((profile[<span class="string">'screen_name'</span>], profile[<span class="string">'followers_count'</span>]))</div><div class="line">profile_file1 = <span class="string">'users/&#123;&#125;/user_profile.json'</span>.format(screen_name1)</div><div class="line">profile_file2 = <span class="string">'users/&#123;&#125;/user_profile.json'</span>.format(screen_name2)</div><div class="line"><span class="keyword">with</span> open(profile_file1) <span class="keyword">as</span> f1, open(profile_file2) <span class="keyword">as</span> f2:</div><div class="line">    profile1 = json.load(f1)</div><div class="line">    profile2 = json.load(f2)</div><div class="line">    followers1 = profile1[<span class="string">'followers_count'</span>]</div><div class="line">    followers2 = profile2[<span class="string">'followers_count'</span>]</div><div class="line">    tweets1 = profile1[<span class="string">'statuses_count'</span>]</div><div class="line">    tweets2 = profile2[<span class="string">'statuses_count'</span>]</div><div class="line"></div><div class="line">sum_reach1 = sum([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> reach1])</div><div class="line">sum_reach2 = sum([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> reach2])</div><div class="line">avg_followers1 = round(sum_reach1 / followers1, <span class="number">2</span>)</div><div class="line">avg_followers2 = round(sum_reach2 / followers2, <span class="number">2</span>)</div><div class="line"></div><div class="line">timeline_file1 = <span class="string">'user_timeline_&#123;&#125;.jsonl'</span>.format(screen_name1)</div><div class="line">timeline_file2 = <span class="string">'user_timeline_&#123;&#125;.jsonl'</span>.format(screen_name2)</div><div class="line"><span class="keyword">with</span> open(timeline_file1) <span class="keyword">as</span> f1, open(timeline_file2) <span class="keyword">as</span> f2:</div><div class="line">    favorite_count1, retweet_count1 = [], []</div><div class="line">    favorite_count2, retweet_count2 = [], []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f1:</div><div class="line">        tweet = json.loads(line)</div><div class="line">        favorite_count1.append(tweet[<span class="string">'favorite_count'</span>])</div><div class="line">        retweet_count1.append(tweet[<span class="string">'retweet_count'</span>])</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f2:</div><div class="line">        tweet = json.loads(line)</div><div class="line">        favorite_count2.append(tweet[<span class="string">'favorite_count'</span>])</div><div class="line">        retweet_count2.append(tweet[<span class="string">'retweet_count'</span>])</div><div class="line">avg_favorite1 = round(sum(favorite_count1) / tweets1, <span class="number">2</span>)</div><div class="line">avg_favorite2 = round(sum(favorite_count2) / tweets2, <span class="number">2</span>)</div><div class="line">avg_retweet1 = round(sum(retweet_count1) / tweets1, <span class="number">2</span>)</div><div class="line">avg_retweet2 = round(sum(retweet_count2) / tweets2, <span class="number">2</span>)</div><div class="line">favorite_per_user1 = round(sum(favorite_count1) / followers1, <span class="number">2</span>)</div><div class="line">favorite_per_user2 = round(sum(favorite_count2) / followers2, <span class="number">2</span>)</div><div class="line">retweet_per_user1 = round(sum(retweet_count1) / followers1, <span class="number">2</span>)</div><div class="line">retweet_per_user2 = round(sum(retweet_count2) / followers2, <span class="number">2</span>)</div><div class="line">print(<span class="string">"----- Stats &#123;&#125; -----"</span>.format(screen_name1))</div><div class="line">print(<span class="string">"&#123;&#125; followers"</span>.format(followers1))</div><div class="line">print(<span class="string">"&#123;&#125; users reached by 1-degree connections"</span>.format(sum_reach1))</div><div class="line">print(<span class="string">"Average number of followers for &#123;&#125;'s followers: &#123;&#125;"</span>.format(screen_name1, avg_followers1))</div><div class="line">print(<span class="string">"Favorited &#123;&#125; times (&#123;&#125; per tweet, &#123;&#125; per user)"</span>.format(sum(favorite_count1), avg_favorite1, favorite_per_user1))</div><div class="line">print(<span class="string">"Retweeted &#123;&#125; times (&#123;&#125; per tweet, &#123;&#125; per user)"</span>.format(sum(retweet_count1), avg_retweet1, retweet_per_user1))</div><div class="line">print(<span class="string">"----- Stats &#123;&#125; -----"</span>.format(screen_name2))</div><div class="line">print(<span class="string">"&#123;&#125; followers"</span>.format(followers2))</div><div class="line">print(<span class="string">"&#123;&#125; users reached by 1-degree connections"</span>.format(sum_reach2))</div><div class="line">print(<span class="string">"Average number of followers for &#123;&#125;'s followers: &#123;&#125;"</span>.format(screen_name2, avg_followers2))</div><div class="line">print(<span class="string">"Favorited &#123;&#125; times (&#123;&#125; per tweet, &#123;&#125; per user)"</span>.format(sum(favorite_count2), avg_favorite2, favorite_per_user2))</div><div class="line">print(<span class="string">"Retweeted &#123;&#125; times (&#123;&#125; per tweet, &#123;&#125; per user)"</span>.format(sum(retweet_count2), avg_retweet2, retweet_per_user2))</div></pre></td></tr></table></figure><pre><code class="md hljs"></code></pre><p>【插入结果】</p><h3 id="用户粉丝分析（description）"><a href="#用户粉丝分析（description）" class="headerlink" title="用户粉丝分析（description）"></a>用户粉丝分析（description）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</div><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</div><div class="line"></div><div class="line">fname = <span class="string">'users/huyong/followers.jsonl'</span> <span class="comment"># 设定文件路径</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> min_ngram &gt; max_ngram:</div><div class="line">    print(<span class="string">"Error: incorrect value for --min-ngram (&#123;&#125;): it can't be higher than --max-value (&#123;&#125;)"</span>.format(min_ngram, max_ngram))</div><div class="line">    sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(fname) <span class="keyword">as</span> f:</div><div class="line">    <span class="comment"># load data</span></div><div class="line">    users = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">        profile = json.loads(line)</div><div class="line">        users.append(profile[<span class="string">'description'</span>])</div><div class="line">    <span class="comment"># create vectorizer</span></div><div class="line">    vectorizer = TfidfVectorizer(max_df= <span class="number">0.8</span>,</div><div class="line">                                 min_df= <span class="number">2</span>,</div><div class="line">                                 max_features= <span class="number">200</span>,</div><div class="line">                                 stop_words=<span class="string">'english'</span>,</div><div class="line">                                 ngram_range=(<span class="number">1</span>, <span class="number">3</span>),</div><div class="line">                                 use_idf= <span class="keyword">True</span>)</div><div class="line">    <span class="comment"># fit data</span></div><div class="line">    X = vectorizer.fit_transform(users)</div><div class="line">    print(<span class="string">"Data dimensions: &#123;&#125;"</span>.format(X.shape))</div><div class="line">    <span class="comment"># perform clustering</span></div><div class="line">    km = KMeans(n_clusters= <span class="number">5</span>)</div><div class="line">    km.fit(X)</div><div class="line">    clusters = defaultdict(list)</div><div class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(km.labels_):</div><div class="line">        clusters[label].append(users[i])</div><div class="line">    <span class="comment"># print 10 user description for this cluster</span></div><div class="line">    <span class="keyword">for</span> label, descriptions <span class="keyword">in</span> clusters.items():</div><div class="line">        print(<span class="string">'---------- Cluster &#123;&#125;'</span>.format(label))</div><div class="line">        <span class="keyword">for</span> desc <span class="keyword">in</span> descriptions[:<span class="number">10</span>]:</div><div class="line">            print(desc)</div></pre></td></tr></table></figure><p>【插入结果】</p><h3 id="用户回应关系分析"><a href="#用户回应关系分析" class="headerlink" title="用户回应关系分析"></a>用户回应关系分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</div><div class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</div><div class="line"></div><div class="line">fname = <span class="string">'CPC china_search.jsonl'</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">with</span> open(fname) <span class="keyword">as</span> f:</div><div class="line">    graph = nx.DiGraph() <span class="comment">#创建有向图</span></div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">        tweet = json.loads(line)</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> <span class="string">'id'</span> <span class="keyword">in</span> tweet:</div><div class="line">            <span class="comment"># 添加节点，</span></div><div class="line">            graph.add_node(tweet[<span class="string">'user'</span>][<span class="string">'id'</span>],</div><div class="line">                           tweet=tweet[<span class="string">'text'</span>],</div><div class="line">                           author=tweet[<span class="string">'user'</span>][<span class="string">'screen_name'</span>],</div><div class="line">                           created_at=tweet[<span class="string">'created_at'</span>])</div><div class="line">            <span class="keyword">if</span> tweet[<span class="string">'in_reply_to_user_id'</span>]:</div><div class="line">                reply_to = tweet[<span class="string">'in_reply_to_user_id'</span>]</div><div class="line">                <span class="keyword">if</span> tweet[<span class="string">'in_reply_to_user_id'</span>] <span class="keyword">in</span> graph \</div><div class="line">                <span class="keyword">and</span> tweet[<span class="string">'user'</span>][<span class="string">'screen_name'</span>] != graph.node[reply_to][<span class="string">'author'</span>]:</div><div class="line">                    graph.add_edge(tweet[<span class="string">'in_reply_to_user_id'</span>], tweet[<span class="string">'user'</span>][<span class="string">'id'</span>])</div><div class="line">    print(nx.info(graph))</div><div class="line"></div><div class="line">    sorted_replied = sorted(graph.degree_iter(), key=itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</div><div class="line">    most_replied_id, replies = sorted_replied[<span class="number">0</span>]</div><div class="line">    print(<span class="string">"Most replied tweet (&#123;&#125; replies):"</span>.format(replies))</div><div class="line">    print(graph.node[most_replied_id])</div><div class="line"></div><div class="line">    print(<span class="string">"Longest discussion:"</span>)</div><div class="line">    longest_path = nx.dag_longest_path(graph)</div><div class="line">    <span class="keyword">for</span> tweet_id <span class="keyword">in</span> longest_path:</div><div class="line">        node = graph.node[tweet_id]</div><div class="line">        print(<span class="string">"&#123;&#125; (by &#123;&#125; at &#123;&#125;)"</span>.format(node[<span class="string">'tweet'</span>],</div><div class="line">                                        node[<span class="string">'author'</span>],</div><div class="line">                                        node[<span class="string">'created_at'</span>]))</div></pre></td></tr></table></figure><p>【插入结果】</p><h1 id="数据的可视化"><a href="#数据的可视化" class="headerlink" title="数据的可视化"></a>数据的可视化</h1><h2 id="推文发布时间序列分析（created-at）"><a href="#推文发布时间序列分析（created-at）" class="headerlink" title="推文发布时间序列分析（created_at）"></a>推文发布时间序列分析（created_at）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> matplotlib.dates <span class="keyword">as</span> mdates</div><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">fname = <span class="string">'user_timeline_PDChina.jsonl'</span></div><div class="line"></div><div class="line"><span class="comment"># 打开指定文件，获取时间字段，将时间索引与计数对应</span></div><div class="line"><span class="keyword">with</span> open(fname, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">    all_dates = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">        tweet = json.loads(line)</div><div class="line">        <span class="comment">#tweet.pop('retweeted_status', &#123;&#125;)</span></div><div class="line">        all_dates.append(tweet.get(<span class="string">'created_at'</span>)) <span class="comment"># 获取时间标签</span></div><div class="line">    ones = np.ones(len(all_dates)) <span class="comment"># 有点像在做计数赋值1</span></div><div class="line">    idx = pd.DatetimeIndex(all_dates) <span class="comment"># 把时间字符转换为真正的时间变量</span></div><div class="line">    my_series = pd.Series(ones, index=idx) <span class="comment"># 把时间和计数对应上</span></div><div class="line">    </div><div class="line">    per_day = my_series.resample(<span class="string">'D'</span>, how=<span class="string">'sum'</span>).fillna(<span class="number">0</span>) <span class="comment"># ‘M’ 表示月 ‘D’ 表示日</span></div><div class="line">    print(my_series.head())</div><div class="line">    print(per_day.head())</div><div class="line">    </div><div class="line">    fig, ax = plt.subplots()</div><div class="line">    ax.grid(<span class="keyword">True</span>)</div><div class="line">    ax.set_title(<span class="string">"Tweet Frequencies"</span>)</div><div class="line">    </div><div class="line">    <span class="comment">#days = mdates.MonthLocator(interval=17) # 月份标记，可以控制月份间隔</span></div><div class="line">    days = mdates.DayLocator(interval=<span class="number">20</span>)</div><div class="line">    date_formatter = mdates.DateFormatter(<span class="string">'%Y-%m-%d'</span>) <span class="comment"># 要注意了，M 是分钟，m 才是月，D 是整个日期，d 是日</span></div><div class="line"></div><div class="line">    <span class="comment"># 最小时间到最大时间</span></div><div class="line">    datemin = datetime(<span class="number">2009</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">    datemax = datetime(<span class="number">2017</span>, <span class="number">11</span>, <span class="number">1</span>)</div><div class="line">    </div><div class="line">    ax.xaxis.set_major_locator(days)</div><div class="line">    ax.xaxis.set_major_formatter(date_formatter)</div><div class="line"> </div><div class="line">    ax.set_xlim(datemin, datemax, auto=<span class="keyword">True</span>)</div><div class="line">    max_freq = per_day.max()</div><div class="line">    ax.set_ylim(<span class="number">0</span>, max_freq)</div><div class="line">    ax.plot(per_day.index, per_day)</div><div class="line"></div><div class="line">    plt.show()</div></pre></td></tr></table></figure><p>数据的摘要：</p><pre><code class="md hljs">2017-11-05 07:01:41    1.02017-11-05 06:35:01    1.02017-11-05 06:10:02    1.02017-11-05 05:50:02    1.02017-11-05 05:24:57    1.0dtype: float642017-08-05    26.02017-08-06    30.02017-08-07    37.02017-08-08    41.02017-08-09    40.0Freq: D, dtype: float64</code></pre><p>所抓取推特中《人民日报》的发推时间序列：</p><p><img src="/images/15099529518854.jpg" alt="推文时间序列"></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">关于<code>OAuth</code> 可参考：<a href="http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html" target="_blank" rel="external">理解 OAuth 2.0</a> 。<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Twitter 的这两种 API 的认证模式可以参考官方介绍：<a href="https://developer.twitter.com/en/docs/basics/authentication/overview/oauth" target="_blank" rel="external">Twitter API Authentication Model</a>。<a href="#fnref:2" rev="footnote"> ↩</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">参见 <a href="https://www.karambelkar.info/2015/01/how-to-use-twitters-search-rest-api-most-effectively./" target="_blank" rel="external">How to use Twitter’s Search REST API most effectively</a>。<a href="#fnref:3" rev="footnote"> ↩</a></span></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">可以参考官方文档 <a href="https://developer.twitter.com/en/docs/basics/rate-limits" target="_blank" rel="external">Rate limits per window</a>。<a href="#fnref:4" rev="footnote"> ↩</a></span></li></ol></div></div>]]></content:encoded>
      
      <comments>http://colin00.github.io/2017/10/20/2017-10-20-1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>怎么理解 Python 爬虫</title>
      <link>http://colin00.github.io/2017/10/20/2017-10-20/</link>
      <guid>http://colin00.github.io/2017/10/20/2017-10-20/</guid>
      <pubDate>Fri, 20 Oct 2017 02:33:44 GMT</pubDate>
      <description>
      
        &lt;p&gt;由于自己的研究需要爬取 Twitter 和 Facebook 的社交数据，但自己又没有真正爬取过，那么我就来好好学习一下啦。&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="/css/lib/hint.min.css"><p>由于自己的研究需要爬取 Twitter 和 Facebook 的社交数据，但自己又没有真正爬取过，那么我就来好好学习一下啦。</p><a id="more"></a> <h1 id="选择一本书"><a href="#选择一本书" class="headerlink" title="选择一本书"></a>选择一本书</h1><p>我选择了《Mastering social media mining with Python》这本书，里面的讲解还是很直接的，干货多方便我快速掌握。本书的代码都能在网站上获取</p><h1 id="了解一些理论"><a href="#了解一些理论" class="headerlink" title="了解一些理论"></a>了解一些理论</h1><p>第一章是 Social media - challenges and opportunities ，讲的是一些爬虫的基本知识，还有一些技术展示，重在培养对爬虫的兴趣。</p><h2 id="对社交媒体的理解"><a href="#对社交媒体的理解" class="headerlink" title="对社交媒体的理解"></a>对社交媒体的理解</h2><p>Internet-based applications<br>User-generated content<br>Networking</p><h2 id="本书要解决的问题"><a href="#本书要解决的问题" class="headerlink" title="本书要解决的问题"></a>本书要解决的问题</h2><p>how to extract useful knowledge from the data coming from the social media?</p><p><strong>knowledge hierarchy</strong></p><h2 id="社交媒体挖掘的机遇"><a href="#社交媒体挖掘的机遇" class="headerlink" title="社交媒体挖掘的机遇"></a>社交媒体挖掘的机遇</h2><p><strong>Application Programming Interface (API)</strong><br><strong>Representational State Transfer (REST)</strong><br><strong>RESTful API</strong></p><h2 id="社交媒体挖掘的挑战"><a href="#社交媒体挖掘的挑战" class="headerlink" title="社交媒体挖掘的挑战"></a>社交媒体挖掘的挑战</h2><p><strong>big data</strong><br><strong>structured data</strong><br><strong>unstructured data</strong><br> <strong>semi-structured data</strong><br> <strong>data integrity</strong><br> <strong>data access</strong><br> <strong>research and development (R&amp;D) processes</strong></p><h2 id="社交媒体挖掘的技术流程"><a href="#社交媒体挖掘的技术流程" class="headerlink" title="社交媒体挖掘的技术流程"></a>社交媒体挖掘的技术流程</h2><p>1、验证 Authentication<br>2、数据收集 Data collection<br>3、数据清理和预处理 Data cleaning and pre-processing<br>4、建模和分析 Modeling and analysis<br>5、结果展示 Result presentation</p><p><img src="http://oyrmgf04y.bkt.clouddn.com/2017-11-03-15084668916933.jpg" alt=""></p><p><strong>Open Authorization (OAuth)</strong><br>a user, consumer (our application), and resource provider (the social media platform).</p><p><strong>Text mining</strong><br><strong>Graph mining</strong></p><h2 id="Python-tools-for-data-science"><a href="#Python-tools-for-data-science" class="headerlink" title="Python tools for data science"></a>Python tools for data science</h2><h3 id="Python-的优点"><a href="#Python-的优点" class="headerlink" title="Python 的优点"></a>Python 的优点</h3><p>Declarative and intuitive syntax<br>Rich ecosystem for data processing<br>Efficiency</p><h3 id="Python-版本"><a href="#Python-版本" class="headerlink" title="Python 版本"></a>Python 版本</h3><p>3.4+ and 3.5+<br>pip and virtualenv<br>virtualenv 管理虚拟环境和安装依赖环境<br>Conda, Anaconda, and Miniconda</p><h3 id="数据分析工具"><a href="#数据分析工具" class="headerlink" title="数据分析工具"></a>数据分析工具</h3><p>NumPy and pandas<br><strong>Naming conventions</strong><br>numpy as np; pandas as pd; </p><h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><p><strong>Supervised learning</strong><br><strong>Naive Bayes (NB)</strong><br><strong>Support Vector Machine (SVM)</strong><br><strong>Neural Networks (NN)</strong><br><strong>training data</strong><br><strong>test data</strong><br><strong>Unsupervised learning</strong></p>]]></content:encoded>
      
      <comments>http://colin00.github.io/2017/10/20/2017-10-20/#disqus_thread</comments>
    </item>
    
    <item>
      <title>终于弄好了～</title>
      <link>http://colin00.github.io/2017/10/19/hello-world/</link>
      <guid>http://colin00.github.io/2017/10/19/hello-world/</guid>
      <pubDate>Thu, 19 Oct 2017 06:05:21 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/css/lib/hint.min.css&quot;&gt;&lt;p&gt;花了一点时间弄这个，可以建一个自己的博客也是很好了。&lt;/p&gt;

        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="/css/lib/hint.min.css"><p>花了一点时间弄这个，可以建一个自己的博客也是很好了。</p>]]></content:encoded>
      
      <comments>http://colin00.github.io/2017/10/19/hello-world/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
